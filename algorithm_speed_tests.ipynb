{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm tests\n",
    "In this notebook, we keep track of algorithm tests. If I am in doubt of whether a certain algorithm is faster or slower, I will test the algorithms using timeit. This will be proof / support for my reasoning about why I make implementation choices.\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pointcloud.Modules.Object import HelperFunctions\n",
    "\n",
    "from numpy import arange as np_arange, array as np_array, frompyfunc as np_frompyfunc, max as np_max, ones as np_ones, sort as np_sort\n",
    "from numpy.random import randint as np_random_randint\n",
    "from scipy.spatial import KDTree as scipy_spatial_KDTree\n",
    "from timeit import timeit\n",
    "from torch import from_numpy as torch_from_numpy\n",
    "from torch_cluster import knn_graph as torch_cluster_knn_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangle area calculation\n",
    "In the first version of the algorithm I calculated all triangle areas with Numpy, but I found out that IGL also has an implementation. The code below commpares both methods! It turns out IGL is around 92% faster than Numpy, which is a significant speedup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.059847648368175424\n"
     ]
    }
   ],
   "source": [
    "NUM_TESTS = 100000\n",
    "algorithm1_str = \"algo1\"\n",
    "algorithm2_str = \"algo2\"\n",
    "\n",
    "input_arguments = \"(example_v, example_f)\"\n",
    "environment = f'''\n",
    "import numpy as np\n",
    "from igl import doublearea as igl_doublearea\n",
    "from numpy import array as np_array, cross as np_cross\n",
    "from numpy.linalg import norm as np_linalg_norm\n",
    "\n",
    "example_v = np_array([[-0.03785068,  0.12783747,  0.00448816],\n",
    " [-0.044779,    0.128887,    0.001905  ],\n",
    " [-0.06801,     0.151244,    0.037195  ],\n",
    " [-0.070454,    0.150585,   -0.043458  ],\n",
    " [-0.031026,    0.153728,   -0.003546  ],\n",
    " [-0.040044,    0.15362,    -0.008167  ]])\n",
    "example_f = np_array([[2, 5, 3],\n",
    " [2, 0, 3],\n",
    " [3, 3, 5],\n",
    " [3, 5, 3],\n",
    " [2, 1, 2],\n",
    " [4, 1, 3]])\n",
    " \n",
    "def {algorithm1_str}(v, f):\n",
    "    triangles = v[f]\n",
    "    As = triangles[...,1,:] - triangles[...,0,:]\n",
    "    Bs = triangles[...,2,:] - triangles[...,0,:]\n",
    "    cross = np_cross(As, Bs, axis=-1)\n",
    "    areas = 0.5*np_linalg_norm(cross, axis=-1)\n",
    "    return areas\n",
    "\n",
    "def {algorithm2_str}(v, f):\n",
    "    return igl_doublearea(v, f) / 2.0\n",
    "'''\n",
    "stmt1 = f\"{algorithm1_str}{input_arguments}\"\n",
    "stmt2 = f\"{algorithm2_str}{input_arguments}\"\n",
    "speed1 = timeit(stmt=stmt1, setup=environment, number=NUM_TESTS)\n",
    "speed2 = timeit(stmt=stmt2, setup=environment, number=NUM_TESTS)\n",
    "print(speed2 / speed1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN graph calculations\n",
    "Calculating the KNN graph can be done with Torch and SciPy. Both give back a different representation of the calculation, but what we want to know is which one is faster in the long run (not counting data structures). With the test below, it can be seen that SciPy is around 70% with the predetermined KDTree datastructure. (Tested for k=2 and k=6 for example vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32600043832805986\n"
     ]
    }
   ],
   "source": [
    "NUM_TESTS = 100000\n",
    "algorithm1_str = \"algo1\"\n",
    "algorithm2_str = \"algo2\"\n",
    "\n",
    "input_arguments1 = \"(example_v, k)\"\n",
    "input_arguments2 = \"(torch_v, k)\"\n",
    "environment = f'''\n",
    "from numpy import array as np_array\n",
    "from scipy.spatial import KDTree as scipy_spatial_KDTree\n",
    "from torch import from_numpy as torch_from_numpy\n",
    "from torch_cluster import knn_graph\n",
    "\n",
    "example_v = np_array([[-0.03785068,  0.12783747,  0.00448816],\n",
    " [-0.044779,    0.128887,    0.001905  ],\n",
    " [-0.06801,     0.151244,    0.037195  ],\n",
    " [-0.070454,    0.150585,   -0.043458  ],\n",
    " [-0.031026,    0.153728,   -0.003546  ],\n",
    " [-0.040044,    0.15362,    -0.008167  ]])\n",
    "k = 2\n",
    "torch_v = torch_from_numpy(example_v)\n",
    "\n",
    "kdtree = scipy_spatial_KDTree(example_v)\n",
    " \n",
    "def {algorithm1_str}(v, k):\n",
    "    return kdtree.query(v, k)\n",
    "\n",
    "def {algorithm2_str}(v, k):\n",
    "    return knn_graph(v, k)\n",
    "'''\n",
    "stmt1 = f\"{algorithm1_str}{input_arguments1}\"\n",
    "stmt2 = f\"{algorithm2_str}{input_arguments2}\"\n",
    "speed1 = timeit(stmt=stmt1, setup=environment, number=NUM_TESTS)\n",
    "speed2 = timeit(stmt=stmt2, setup=environment, number=NUM_TESTS)\n",
    "print(speed1 / speed2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HelperFunctions.toEdgeTensor works\n",
    "This section is here just to check whether the functionality of toEdgeTensor works. We compare the result with knn_graph from the torch.cluster package. If the edges are the same in both tensors, the conversion is done correctly.\n",
    "### Result\n",
    "It can be seen that the results have almost the same size. The difference is that the scipy variant contains self-loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 18]) (6, 3)\n",
      "torch.Size([2, 18]) torch.Size([2, 18])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5],\n",
      "        [1, 4, 5, 0, 5, 4, 1, 0, 5, 5, 4, 1, 5, 0, 1, 4, 1, 0]])\n",
      "tensor([[1, 4, 5, 0, 5, 4, 1, 0, 5, 5, 4, 1, 5, 0, 1, 4, 1, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5]])\n"
     ]
    }
   ],
   "source": [
    "example_v = np_array([[-0.03785068,  0.12783747,  0.00448816],\n",
    " [-0.044779,    0.128887,    0.001905  ],\n",
    " [-0.06801,     0.151244,    0.037195  ],\n",
    " [-0.070454,    0.150585,   -0.043458  ],\n",
    " [-0.031026,    0.153728,   -0.003546  ],\n",
    " [-0.040044,    0.15362,    -0.008167  ]])\n",
    "k = 3\n",
    "original = torch_cluster_knn_graph(torch_from_numpy(example_v), k=k)\n",
    "kdtree = scipy_spatial_KDTree(example_v)\n",
    "result = kdtree.query(example_v, k=k+1)[1][:, 1:]\n",
    "print(original.size(), result.shape)\n",
    "conversion = HelperFunctions.toEdgeTensor(result)\n",
    "print(conversion.size(), original.size())\n",
    "print(conversion)\n",
    "print(original)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Uniques\n",
    "Pandas' unique function seems to be faster than Numpy's unique function. Panda only doesn't sort.. But even with sorting it seems to be faster. We also compare Torch's unique, since we wanna compare all uniques!\n",
    "### Results (old)\n",
    "As a clear result, we can see that Torch or Numpy should be used for unique calculations. Not Pandas! Also, you should not convert from one or the other just to use the unique functionality. This is also slower!\n",
    "### New Results!\n",
    "Scrap everything! Never use unique anymore if you only need the uniques! Use sets!!!\n",
    "### Final conclusions!\n",
    " ---> Always use sets to calculate uniques, but not if you need counts or inverses. Then use uniques. Also! When using Torch, use Torch's unique and not sets, because conversions take too much time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy: 0.5249346999999993\n",
      "Pandas: 1.8982664999999983\n",
      "Torch: 0.5124120000000012\n",
      "Python Set Arrays: 0.12064409999999981\n",
      "Python Set Tensors: 0.8196423999999993\n"
     ]
    }
   ],
   "source": [
    "NUM_TESTS = 100000\n",
    "algorithm1_str = \"algo1\"\n",
    "algorithm2_str = \"algo2\"\n",
    "algorithm3_str = \"algo2asdf\"\n",
    "algorithm4_str = \"algkasjdf\"\n",
    "algorithm5_str = \"algkasadfsadfsadfsjdf\"\n",
    "\n",
    "input_arguments1 = \"(numpy_v)\"\n",
    "input_arguments2 = \"(pandas_v)\"\n",
    "input_arguments3 = \"(torch_v)\"\n",
    "input_arguments4 = \"(numpy_v)\"\n",
    "input_arguments5 = \"(torch_v)\"\n",
    "environment = f'''\n",
    "from numpy import array as np_array, unique as np_unique\n",
    "from numpy.random import randint as np_random_randint\n",
    "from pandas import Series as pd_Series, unique as pandas_unique\n",
    "from torch import from_numpy as torch_from_numpy, unique as torch_unique, Tensor as torch_tensor\n",
    "\n",
    "numpy_v = np_random_randint(10, 20, 10)\n",
    "torch_v = torch_from_numpy(numpy_v)\n",
    "pandas_v = pd_Series(numpy_v)\n",
    " \n",
    "def {algorithm1_str}(v):\n",
    "    return np_unique(v)\n",
    "\n",
    "def {algorithm2_str}(v):\n",
    "    return pandas_unique(v)\n",
    "    \n",
    "def {algorithm3_str}(v):\n",
    "    return torch_unique(v)\n",
    "\n",
    "def {algorithm4_str}(v):\n",
    "    return np_array(list(set(v.tolist())))\n",
    "\n",
    "def {algorithm5_str}(v):\n",
    "    return torch_tensor(list(set(v.tolist()))).int()\n",
    "'''\n",
    "stmt1 = f\"{algorithm1_str}{input_arguments1}\"\n",
    "stmt2 = f\"{algorithm2_str}{input_arguments2}\"\n",
    "stmt3 = f\"{algorithm3_str}{input_arguments3}\"\n",
    "stmt4 = f\"{algorithm4_str}{input_arguments4}\"\n",
    "stmt5 = f\"{algorithm5_str}{input_arguments5}\"\n",
    "speed1 = timeit(stmt=stmt1, setup=environment, number=NUM_TESTS)\n",
    "speed2 = timeit(stmt=stmt2, setup=environment, number=NUM_TESTS)\n",
    "speed3 = timeit(stmt=stmt3, setup=environment, number=NUM_TESTS)\n",
    "speed4 = timeit(stmt=stmt4, setup=environment, number=NUM_TESTS)\n",
    "speed5 = timeit(stmt=stmt5, setup=environment, number=NUM_TESTS)\n",
    "results = np_array([speed1, speed2, speed3, speed4, speed5])\n",
    "print(f\"Numpy: {results[0]}\\nPandas: {results[1]}\\nTorch: {results[2]}\\nPython Set Arrays: {results[3]}\\nPython Set Tensors: {results[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 11 12 13 15 18]\n",
      "[10 15 18 11 12 13]\n",
      "tensor([10, 11, 12, 13, 15, 18], dtype=torch.int32)\n",
      "[10 11 12 13 15 18]\n",
      "tensor([10, 11, 12, 13, 15, 18], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "from numpy import array as np_array, unique as np_unique\n",
    "from numpy.random import randint as np_random_randint\n",
    "from pandas import Series as pd_Series, unique as pandas_unique\n",
    "from torch import from_numpy as torch_from_numpy, Tensor as torch_tensor, unique as torch_unique\n",
    "\n",
    "numpy_v = np_random_randint(10, 20, 10)\n",
    "torch_v = torch_from_numpy(numpy_v)\n",
    "pandas_v = pd_Series(numpy_v)\n",
    " \n",
    "def algorithm1_str(v):\n",
    "    return np_unique(v)\n",
    "\n",
    "def algorithm2_str(v):\n",
    "    return pandas_unique(v)\n",
    "    \n",
    "def algorithm3_str(v):\n",
    "    return torch_unique(v)\n",
    "\n",
    "def algorithm4_str(v):\n",
    "    return np_array(list(set(v.tolist())))\n",
    "\n",
    "def algorithm5_str(v):\n",
    "    return torch_tensor(list(set(v.tolist()))).int()\n",
    "\n",
    "print(algorithm1_str(numpy_v))\n",
    "print(algorithm2_str(pandas_v))\n",
    "print(algorithm3_str(torch_v))\n",
    "print(algorithm4_str(numpy_v))\n",
    "print(algorithm5_str(torch_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FromPyFunc or CumSum\n",
    "When having multiple ranges and wanting all the unique indices that fall in one of the ranges, there are two methods to compute these values now. When comparing, using the new method stolen from stackoverflow is faster than the old version where FromPyFunc was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundaries2indices: 10.733755299999999\n",
      "old frompyfunc: 19.1546478\n"
     ]
    }
   ],
   "source": [
    "NUM_TESTS = 100000\n",
    "algorithm1_str = \"algo1\"\n",
    "algorithm2_str = \"algo2\"\n",
    "\n",
    "input_arguments1 = \"(starts, stops)\"\n",
    "input_arguments2 = \"(starts, stops)\"\n",
    "environment = f'''\n",
    "from numpy import arange as np_arange, array as np_array, frompyfunc as np_frompyfunc, ones as np_ones\n",
    "from numpy.random import randint as np_random_randint\n",
    "\n",
    "starts = np_random_randint(10, 20, 100)\n",
    "stops = np_random_randint(30, 40, 100)\n",
    "\n",
    " \n",
    "def {algorithm1_str}(starts, stops):\n",
    "    l = stops - starts\n",
    "    clens = l.cumsum()\n",
    "    ids = np_ones(clens[-1],dtype=int)\n",
    "    ids[0] = starts[0]\n",
    "    ids[clens[:-1]] = starts[1:] - stops[:-1]+1\n",
    "    return np_array(list(set(ids.cumsum())))\n",
    "\n",
    "def {algorithm2_str}(starts, stops):\n",
    "    ranges = np_frompyfunc(np_arange, 2, 1)(starts, stops)\n",
    "    uniqueFaces = set()\n",
    "    for range in ranges:\n",
    "        uniqueFaces.update(range)\n",
    "    return np_array(list(uniqueFaces))\n",
    "'''\n",
    "stmt1 = f\"{algorithm1_str}{input_arguments1}\"\n",
    "stmt2 = f\"{algorithm2_str}{input_arguments2}\"\n",
    "speed1 = timeit(stmt=stmt1, setup=environment, number=NUM_TESTS)\n",
    "speed2 = timeit(stmt=stmt2, setup=environment, number=NUM_TESTS)\n",
    "results = np_array([speed1, speed2])\n",
    "print(f\"boundaries2indices: {results[0]}\\nold frompyfunc: {results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 1868\n",
      "[  24   25   26   27   28   29   30   31   32   53   54   55   56   57\n",
      "   75   76   77   78   79  101  102  103  104  105  159  160  161  162\n",
      "  163  180  181  182  183  184  221  222  223  224  225  235  236  237\n",
      "  238  239  297  298  299  300  301  318  319  320  321  322  326  327\n",
      "  328  329  330  349  350  351  352  353  369  370  371  372  373  462\n",
      "  463  464  465  466  467  468  469  470  471  579  580  581  582  583\n",
      "  584  585  586  587  588  608  609  610  611  612  670  671  672  673\n",
      "  674  730  731  732  733  734  771  772  773  774  775  777  778  779\n",
      "  780  781  782  799  800  801  802  803  840  841  842  843  844  845\n",
      "  846  847  848  849  921  922  923  924  925  943  944  945  946  947\n",
      "  960  961  962  963  964 1044 1045 1046 1047 1048 1104 1105 1106 1107\n",
      " 1108 1181 1182 1183 1184 1185 1295 1296 1297 1298 1299 1362 1363 1364\n",
      " 1365 1366 1370 1371 1372 1373 1374 1377 1378 1379 1380 1381 1440 1441\n",
      " 1442 1443 1444 1502 1503 1504 1505 1506 1551 1552 1553 1554 1555 1569\n",
      " 1570 1571 1572 1573 1612 1613 1614 1615 1616 1617 1618 1619 1620 1744\n",
      " 1745 1746 1747 1748 1749 1750 1751 1752 1753 1778 1779 1780 1781 1782\n",
      " 1785 1786 1787 1788 1789 1819 1820 1821 1822 1823 1863 1864 1865 1866\n",
      " 1867]\n",
      "[  24   25   26   27   28   29   30   31   32   53   54   55   56   57\n",
      "   75   76   77   78   79  101  102  103  104  105  159  160  161  162\n",
      "  163  180  181  182  183  184  221  222  223  224  225  235  236  237\n",
      "  238  239  297  298  299  300  301  318  319  320  321  322  326  327\n",
      "  328  329  330  349  350  351  352  353  369  370  371  372  373  462\n",
      "  463  464  465  466  467  468  469  470  471  579  580  581  582  583\n",
      "  584  585  586  587  588  608  609  610  611  612  670  671  672  673\n",
      "  674  730  731  732  733  734  771  772  773  774  775  777  778  779\n",
      "  780  781  782  799  800  801  802  803  840  841  842  843  844  845\n",
      "  846  847  848  849  921  922  923  924  925  943  944  945  946  947\n",
      "  960  961  962  963  964 1044 1045 1046 1047 1048 1104 1105 1106 1107\n",
      " 1108 1181 1182 1183 1184 1185 1295 1296 1297 1298 1299 1362 1363 1364\n",
      " 1365 1366 1370 1371 1372 1373 1374 1377 1378 1379 1380 1381 1440 1441\n",
      " 1442 1443 1444 1502 1503 1504 1505 1506 1551 1552 1553 1554 1555 1569\n",
      " 1570 1571 1572 1573 1612 1613 1614 1615 1616 1617 1618 1619 1620 1744\n",
      " 1745 1746 1747 1748 1749 1750 1751 1752 1753 1778 1779 1780 1781 1782\n",
      " 1785 1786 1787 1788 1789 1819 1820 1821 1822 1823 1863 1864 1865 1866\n",
      " 1867]\n"
     ]
    }
   ],
   "source": [
    "data = np_random_randint(0, 2000, 100).reshape(2, -1)\n",
    "data[1] = data[0] + 5\n",
    "\n",
    " \n",
    "def algorithm1_str(starts, stops):\n",
    "    l = stops - starts\n",
    "    clens = l.cumsum()\n",
    "    ids = np_ones(clens[-1],dtype=int)\n",
    "    ids[0] = starts[0]\n",
    "    ids[clens[:-1]] = starts[1:] - stops[:-1]+1\n",
    "    return np_array(list(set(ids.cumsum())))\n",
    "\n",
    "def algorithm2_str(starts, stops):\n",
    "    ranges = np_frompyfunc(np_arange, 2, 1)(starts, stops)\n",
    "    uniqueFaces = set()\n",
    "    for range in ranges:\n",
    "        uniqueFaces.update(range)\n",
    "    return np_array(list(uniqueFaces))\n",
    "\n",
    "print(min(data[0]), max(data[1]))\n",
    "print(np_sort(algorithm1_str(data[0], data[1])))\n",
    "print(np_sort(algorithm2_str(data[0], data[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PCDenoiser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
