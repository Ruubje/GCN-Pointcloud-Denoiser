{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class descriptions\n",
    "PatchDataset should return a collection of patch files to be used for training or validation.\n",
    "DatasetManager should be a new class that handles and selects patch datasets.\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PatchGeneration.Modules.Network.datautils import *\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test datamanager\n",
    "Testing the datamanager by selecting a folder with datapoints, generating a dataset and splitting it 20%-80% validation-training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataManager = DatasetManager(batch_size=100)\n",
    "dataManager.addFolder(\"samples/Test_Bunny\")\n",
    "dataManager.generateDatasetFromFolders()\n",
    "dataManager.splitData(0.2)\n",
    "trainingSet = dataManager.getTrainingSet()\n",
    "validationSet = dataManager.getValidationSet()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some print statements as proof that the split is a split and both contain all datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "8\n",
      "Validation data:\n",
      "2\n",
      "[]\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data:\")\n",
    "print(len(trainingSet))\n",
    "print(\"Validation data:\")\n",
    "print(len(validationSet))\n",
    "print(np.intersect1d(trainingSet.dataset.data_path, validationSet.dataset.data_path))\n",
    "print(np.all(np.isin(np.union1d(trainingSet.dataset.data_path, validationSet.dataset.data_path), dataManager.data_path)))\n",
    "print(np.all(np.isin(dataManager.data_path, np.union1d(trainingSet.dataset.data_path, validationSet.dataset.data_path))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Saving and Loading\n",
    "Testing saving a loading the dataset and split into files with nonsense names. (When saving to a non-existing subdirectory, a directory will remain present after removing the file, therefore the code is saving to the current directory!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"TESTDATAESST_JWZ.h5\"\n",
    "dataManager.saveDataset(DATASET_NAME)\n",
    "dataManager.loadDataset(DATASET_NAME)\n",
    "os.remove(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_NAME = \"JWZSPLITTHESHIT.npy\"\n",
    "dataManager.saveSplit(SPLIT_NAME)\n",
    "dataManager.loadSplit(SPLIT_NAME)\n",
    "os.remove(SPLIT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 20, 64]) tensor([[[4.9404e-01, 4.9629e-01, 5.0000e-01,  ..., 3.5917e-01,\n",
      "          4.9700e-01, 4.8361e-01],\n",
      "         [6.0233e-01, 5.0503e-01, 5.0000e-01,  ..., 1.0400e+00,\n",
      "          6.5421e-01, 7.5234e-01],\n",
      "         [3.6399e-01, 3.9227e-01, 5.0000e-01,  ..., 6.1746e-01,\n",
      "          1.0076e+00, 9.6782e-01],\n",
      "         ...,\n",
      "         [1.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 4.7000e+01,\n",
      "          3.6000e+01, 3.3000e+01],\n",
      "         [4.0000e+00, 2.0000e+00, 3.0000e+00,  ..., 6.0000e+01,\n",
      "          6.3000e+01, 6.2000e+01],\n",
      "         [1.3000e+01, 5.0000e+00, 8.0000e+00,  ..., 6.0000e+01,\n",
      "          6.3000e+01, 6.2000e+01]],\n",
      "\n",
      "        [[4.9696e-01, 5.0000e-01, 5.1557e-01,  ..., 4.5721e-01,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [4.7630e-01, 5.0000e-01, 6.0547e-01,  ..., 1.5952e-01,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.8938e-01, 5.0000e-01, 5.0951e-01,  ..., 1.1182e-02,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [1.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 4.5000e+01,\n",
      "          6.3000e+01, 6.3000e+01],\n",
      "         [4.0000e+00, 2.0000e+00, 3.0000e+00,  ..., 6.0000e+01,\n",
      "          6.3000e+01, 6.3000e+01],\n",
      "         [5.0000e+00, 8.0000e+00, 1.2000e+01,  ..., 6.0000e+01,\n",
      "          6.3000e+01, 6.3000e+01]],\n",
      "\n",
      "        [[5.0469e-01, 4.5667e-01, 4.4934e-01,  ..., 5.0573e-01,\n",
      "          4.7097e-01, 4.5224e-01],\n",
      "         [5.6786e-01, 5.4373e-01, 4.2792e-01,  ..., 7.6401e-02,\n",
      "          2.4450e-02, 8.5714e-03],\n",
      "         [4.2994e-01, 3.3514e-01, 3.0163e-01,  ..., 8.9513e-01,\n",
      "          1.5588e-01, 2.4798e-01],\n",
      "         ...,\n",
      "         [1.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 5.3000e+01,\n",
      "          6.3000e+01, 4.2000e+01],\n",
      "         [5.0000e+00, 2.0000e+00, 3.0000e+00,  ..., 6.0000e+01,\n",
      "          6.3000e+01, 6.2000e+01],\n",
      "         [1.1000e+01, 1.7000e+01, 3.0000e+01,  ..., 6.0000e+01,\n",
      "          6.3000e+01, 6.2000e+01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[5.1918e-01, 4.9707e-01, 5.1178e-01,  ..., 5.8130e-01,\n",
      "          5.4385e-01, 5.8454e-01],\n",
      "         [2.9395e-01, 3.5361e-01, 4.4894e-01,  ..., 1.0808e+00,\n",
      "          1.0096e+00, 1.0569e+00],\n",
      "         [4.8891e-01, 4.1303e-01, 4.1519e-01,  ..., 5.9771e-01,\n",
      "          6.9606e-01, 4.8406e-01],\n",
      "         ...,\n",
      "         [1.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 6.2000e+01,\n",
      "          3.5000e+01, 5.0000e+01],\n",
      "         [5.0000e+00, 2.0000e+00, 3.0000e+00,  ..., 6.3000e+01,\n",
      "          6.1000e+01, 6.1000e+01],\n",
      "         [2.3000e+01, 1.3000e+01, 7.0000e+00,  ..., 6.3000e+01,\n",
      "          6.1000e+01, 6.1000e+01]],\n",
      "\n",
      "        [[5.1165e-01, 4.7893e-01, 4.8938e-01,  ..., 4.5338e-01,\n",
      "          4.7425e-01, 4.4700e-01],\n",
      "         [4.3034e-01, 4.9601e-01, 5.7685e-01,  ..., 4.1721e-01,\n",
      "          5.2186e-01, 9.5280e-01],\n",
      "         [6.4897e-01, 6.8978e-01, 6.5960e-01,  ..., 6.1456e-05,\n",
      "          8.6114e-03, 3.7400e-01],\n",
      "         ...,\n",
      "         [1.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 5.7000e+01,\n",
      "          3.5000e+01, 3.6000e+01],\n",
      "         [5.0000e+00, 2.0000e+00, 3.0000e+00,  ..., 6.2000e+01,\n",
      "          6.1000e+01, 3.6000e+01],\n",
      "         [1.6000e+01, 2.4000e+01, 2.2000e+01,  ..., 6.2000e+01,\n",
      "          6.1000e+01, 3.6000e+01]],\n",
      "\n",
      "        [[5.0796e-01, 5.0000e-01, 5.0367e-01,  ..., 3.8468e-01,\n",
      "          4.0607e-01, 5.4565e-01],\n",
      "         [5.9748e-01, 5.0000e-01, 4.0981e-01,  ..., 8.4554e-01,\n",
      "          7.7280e-01, 7.3233e-03],\n",
      "         [5.4915e-01, 5.0000e-01, 5.5720e-01,  ..., 1.2539e-01,\n",
      "          7.5432e-02, 3.9870e-01],\n",
      "         ...,\n",
      "         [1.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 5.5000e+01,\n",
      "          4.3000e+01, 3.3000e+01],\n",
      "         [5.0000e+00, 2.0000e+00, 3.0000e+00,  ..., 6.2000e+01,\n",
      "          6.1000e+01, 3.3000e+01],\n",
      "         [8.0000e+00, 7.0000e+00, 1.0000e+01,  ..., 6.2000e+01,\n",
      "          6.1000e+01, 3.3000e+01]]])\n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate(dataManager.getValidationSet()):\n",
    "    inputs, _, _, _ = v\n",
    "    inputs = inputs.type(torch.FloatTensor)\n",
    "    inputs = inputs.permute(0, 2, 1)\n",
    "    print(inputs.shape, inputs)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(type(0.1) == float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PCDenoiser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
